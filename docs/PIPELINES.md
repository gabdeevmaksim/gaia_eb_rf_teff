## Complete Pipeline System âœ…

I've created a complete pipeline orchestration system for your project! Here's what's been built:

---

### **What Was Created**

#### **1. Pipeline Framework**

**`src/pipeline/base.py`** - Base pipeline classes
- `PipelineStep` - Base class for pipeline steps
- `Pipeline` - Orchestrates multiple steps sequentially
- Automatic timing, logging, error handling
- Status tracking and reporting

**`src/pipeline/data_pipeline.py`** - Data processing pipeline
- `ConvertECSVStep` - Convert ECSV to Parquet
- `ExtractDuplicatesStep` - Extract Pan-STARRS duplicates
- `MergeDuplicatesStep` - Merge duplicates with weighted averaging
- `CleanPhotometryStep` - Clean and filter photometry
- `CalculateTemperaturesStep` - Calculate effective temperatures
- `DataProcessingPipeline` - Complete data pipeline

**`src/pipeline/ml_pipeline.py`** - ML training pipeline
- `LoadMLDataStep` - Load ML training data
- `FeatureEngineeringStep` - Engineer all features
- `PrepareTrainTestStep` - Create train/test split
- `TrainModelStep` - Train Random Forest model
- `EvaluateModelStep` - Calculate performance metrics
- `SaveModelStep` - Save model and artifacts
- `MLTrainingPipeline` - Complete ML pipeline

**`pipeline.py`** - Master orchestrator (command-line interface)
- Run individual pipelines
- Run complete end-to-end workflow
- Dry-run mode
- Custom parameters

---

### **Quick Start**

#### **Run Pipelines**

```bash
# ML training (requires --ml-config)
python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml

# Prediction (input from data/raw by default when source_location: raw in config)
python pipeline.py --predict --pred-config config/prediction/predict_gaia_teff_corrected_log_optuna.yaml

# Validation (uses test predictions from training)
python pipeline.py --validate --val-config config/validation/validate_gaia_teff_flag1_corrected_optuna.yaml
```

#### **Custom Parameters**

```bash
# Train with custom hyperparameters (legacy; prefer editing model config)
python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml --n-estimators 500 --max-depth 25
```

#### **Dry Run**

```bash
python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml --dry-run
```

---

### **Pipeline Architecture**

```
Master Pipeline (pipeline.py)
â”‚
â”œâ”€â”€ ML Training (--ml --ml-config config/models/*.yaml)
â”‚   ConfigurableMLPipeline: load config â†’ load data (from data/raw or data/processed)
â”‚   â†’ Teff correction â†’ preprocess â†’ features â†’ train/test split â†’ Optuna (optional)
â”‚   â†’ train RF â†’ evaluate â†’ save model + metadata + test predictions
â”‚
â”œâ”€â”€ Prediction (--predict --pred-config config/prediction/*.yaml)
â”‚   Load model, load data (from config source_location), predict â†’ save parquet
â”‚
â”œâ”€â”€ Validation (--validate --val-config config/validation/*.yaml)
â”‚   Load model + test predictions â†’ metrics + plots â†’ reports/figures/
â”‚
â””â”€â”€ Data (--data) â€” optional upstream: convert/clean data; this repo typically
    uses input from HuggingFace (data/raw/eb_unified_photometry.parquet).
```

---

### **Features**

#### **Automatic Logging**

Each pipeline step logs:
- âœ“ Start/end times
- âœ“ Duration
- âœ“ Status (pending/running/completed/failed)
- âœ“ Progress indicators
- âœ“ Summary at end

Example output:
```
[1/5] Convert ECSV to Parquet
  âœ“ Completed step: Convert ECSV to Parquet
  Duration: 15.3s

[2/5] Extract Pan-STARRS Duplicates
  âœ“ Completed step: Extract Pan-STARRS Duplicates
  Duration: 8.7s

...

PIPELINE SUMMARY
================
  [1] âœ“ Convert ECSV to Parquet: completed (15.3s)
  [2] âœ“ Extract Pan-STARRS Duplicates: completed (8.7s)
  ...
Total duration: 245.2s
Status: âœ“ All steps completed successfully
```

#### **Error Handling**

- Each step wrapped in try/catch
- Errors logged with full traceback
- Pipeline stops on error but shows summary
- Failed steps clearly indicated

#### **Shared Context**

Steps share data via context dictionary:
```python
{
    'config': Config(),
    'ml_data': DataFrame,
    'model': RandomForestRegressor,
    'metrics': {...},
    'model_id': 'rf_temperature_regressor_20251003_120000',
    ...
}
```

#### **Reusability**

All pipelines use the same reusable code:
- Configuration system
- Feature engineering functions
- Data loading utilities
- Scripts (as library functions)

---

### **Usage Examples**

#### **1. Get Input Data**

```bash
# Download input photometry from HuggingFace (saves to data/raw/)
python scripts/download_datasets.py --datasets training
```

Input: `data/raw/eb_unified_photometry.parquet`. The merge script produces `data/processed/eb_catalog_teff.parquet` from this plus prediction parquets.

#### **2. Train a New Model**

```bash
# Train with a model config (data path comes from config: source_location + source_file)
python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml

# Dry run first
python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml --dry-run
```

This will:
1. Load model config and (optionally) cached Optuna hyperparameters
2. Load training data from `data/raw/` or `data/processed/` per config
3. Apply Teff correction, preprocess, engineer features
4. Train/test split, train RF, evaluate, save model + metadata + test predictions

Output: `models/rf_<id_prefix>_<timestamp>.pkl`, `_metadata.json`, `_test_predictions.parquet`, etc.

#### **3. Prediction and validation**

```bash
# Predict (input from data/raw when source_location: raw in prediction config)
python pipeline.py --predict --pred-config config/prediction/predict_gaia_teff_corrected_log_optuna.yaml

# Validate (uses test predictions from training)
python pipeline.py --validate --val-config config/validation/validate_gaia_teff_flag1_corrected_optuna.yaml
```

---

### **Programmatic Usage**

```python
from src.pipeline import ConfigurableMLPipeline, PredictionPipeline, ValidationPipeline

# Train (uses config for data path and hyperparameters)
pipeline = ConfigurableMLPipeline('config/models/gaia_teff_corrected_log_optuna.yaml')
context = pipeline.run()
model_id = context.get('model_id')
metrics = context.get('metrics', {})

# Predict
pred = PredictionPipeline('config/prediction/predict_gaia_teff_corrected_log_optuna.yaml')
pred.run()

# Validate
val = ValidationPipeline('config/validation/validate_gaia_teff_flag1_corrected_optuna.yaml')
val.run()
```

---

### **Creating Custom Pipelines**

You can easily create custom pipelines:

```python
from src.pipeline.base import Pipeline, PipelineStep

class MyCustomStep(PipelineStep):
    def __init__(self):
        super().__init__("My Custom Step")

    def run(self, context):
        # Your logic here
        self.logger.info("Doing custom work...")

        # Add to context
        context['my_result'] = ...

        return context

class MyCustomPipeline(Pipeline):
    def __init__(self):
        steps = [
            MyCustomStep(),
            # ... more steps
        ]
        super().__init__("My Custom Pipeline", steps)

# Run it
pipeline = MyCustomPipeline()
context = pipeline.run()
```

---

### **Command-Line Interface**

```bash
$ python pipeline.py --help

usage: pipeline.py [-h] (--all | --data | --ml | --predict | --validate)
                    [--ml-config PATH] [--pred-config PATH] [--val-config PATH]
                    [--n-estimators N] [--max-depth N] [--dry-run] [-v]

Eclipsing Binary Temperature Analysis Pipeline

Pipeline selection (one required):
  --all                 Run complete pipeline (data + ML)
  --data                Run data processing only
  --ml                  Run ML training only (use --ml-config for model)
  --predict             Run prediction only (use --pred-config)
  --validate            Run validation only (use --val-config)

Configuration:
  --ml-config PATH      Model config (e.g. config/models/gaia_teff_corrected_log_optuna.yaml)
  --pred-config PATH    Prediction config (e.g. config/prediction/predict_gaia_teff_flag1_corrected_optuna.yaml)
  --val-config PATH     Validation config (e.g. config/validation/validate_gaia_teff_flag1_corrected_optuna.yaml)

Options:
  --dry-run             Show what would be executed
  -v, --verbose         Verbose logging
  --n-estimators N      (Legacy) Override trees; prefer --ml-config
  --max-depth N         (Legacy) Override depth; prefer --ml-config

Examples:
  python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml
  python pipeline.py --predict --pred-config config/prediction/predict_gaia_teff_flag1_corrected_optuna.yaml
  python pipeline.py --validate --val-config config/validation/validate_gaia_teff_flag1_corrected_optuna.yaml
  python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml --dry-run
```

---

### **Integration with Existing Code**

Pipelines reuse all existing code:
- âœ… Scripts (`scripts/*.py`) - imported as functions
- âœ… Configuration (`config/config.yaml`) - automatic
- âœ… Feature engineering (`src/features/`) - direct import

No code duplication!

---

### **Benefits**

âœ… **Automated** - Run entire workflow with one command
âœ… **Reproducible** - Same code, same results
âœ… **Logged** - Full execution history
âœ… **Robust** - Error handling and recovery
âœ… **Flexible** - Run partial pipelines
âœ… **Reusable** - Same code in notebooks, scripts, pipelines
âœ… **Production-ready** - Can be deployed to production

---

### **Directory Structure**

```
â”œâ”€â”€ pipeline.py                    # âœ¨ Master pipeline CLI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline/                  # âœ¨ Pipeline modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py               # Base classes
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py      # Data processing
â”‚   â”‚   â””â”€â”€ ml_pipeline.py        # ML training
â”‚   â”œâ”€â”€ features/                  # Reusable features
â”‚   â””â”€â”€ config/                    # Configuration
â”œâ”€â”€ scripts/                       # Individual scripts
â”œâ”€â”€ notebooks/                     # Interactive analysis
â””â”€â”€ config/
    â””â”€â”€ config.yaml               # Central config
```

---

### **Next Steps**

1. **Train a model (recommended):**
   ```bash
   python pipeline.py --ml --ml-config config/models/gaia_teff_corrected_log_optuna.yaml
   ```

2. **Run prediction:**
   ```bash
   python pipeline.py --predict --pred-config config/prediction/predict_gaia_teff_flag1_corrected_optuna.yaml
   ```

3. **Validate a model:**
   ```bash
   python pipeline.py --validate --val-config config/validation/validate_gaia_teff_flag1_corrected_optuna.yaml
   ```

4. **Dry run:** add `--dry-run` to any command to see the execution plan without running.

5. **Schedule automated runs:**
   ```bash
   # crontab
   0 2 * * * cd /path/to/project && python pipeline.py --ml
   ```

---

### **Documentation Files**

- **This file**: `docs/PIPELINES.md`
- Configuration: `docs/CONFIGURATION.md`
- Notebooks: `docs/NOTEBOOK_GUIDE.md`

---

## Summary

âœ… **Created**: Complete pipeline orchestration system
âœ… **Automated**: Data processing + ML training
âœ… **Reusable**: Same code everywhere (scripts/notebooks/pipelines)
âœ… **Production-ready**: Logging, error handling, CLI
âœ… **Documented**: Complete guide with examples

You can now run your entire analysis workflow with a single command:

```bash
python pipeline.py --all
```

**Everything is connected and automated!** ðŸš€
